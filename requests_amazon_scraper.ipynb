{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time()\n",
    "URL = \" https://www.amazon.com/Arm-Hammer-Booster-Purifying-Waters/dp/B08T7X7XYX?pd_rd_w=UPYP1&content-id=amzn1.sym.80bfd2e5-c81d-48d5-ae85-c500e2214af9&pf_rd_p=80bfd2e5-c81d-48d5-ae85-c500e2214af9&pf_rd_r=P3BJ0XMXPK4K68KFG564&pd_rd_wg=a6oPV&pd_rd_r=9a304aff-d87b-4135-b186-63dca4d76e6c&pd_rd_i=B08T7X7XYX&psc=1&ref_=pd_bap_d_csi_pd_ys_c_rfy_rp_crs_6_t\"\n",
    "HEADERS = {\n",
    "    \"method\": \"GET\",\n",
    "\n",
    "    \"accept-encoding\": \"gzip, deflate, br\",\n",
    "\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\",\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "response = requests.get(URL, headers=HEADERS)\n",
    "#print(response.content)\n",
    "# with open(\"myfile.html\", \"w\") as file1:\n",
    "#     # Writing data to a file\n",
    "#     file1.write(str(response.content))\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "\n",
    "see_all_reviews_link = soup.find(\"a\", {\"data-hook\": \"see-all-reviews-link-foot\"})[\"href\"]\n",
    "\n",
    "\n",
    "URL_ALL_REVIEWS = \"https://www.amazon.com/\" + see_all_reviews_link\n",
    "\n",
    "\n",
    "response = requests.get(URL_ALL_REVIEWS, headers=HEADERS)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "\n",
    "# Find the element that contains the ratings with reviews and extract the text\n",
    "ratings_with_reviews_elem = soup.find(\"div\", {\"id\": \"filter-info-section\"})\n",
    "ratings_with_reviews_text = ratings_with_reviews_elem.get_text().strip()\n",
    "\n",
    "#get just the reviews amount\n",
    "reviews_count = re.search(r'(\\d+,*\\d*)\\s+with reviews', ratings_with_reviews_text).group(1)\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "def scrape_reviews(page_url):\n",
    "    response = requests.get(page_url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    reviews = soup.find_all('div', {'data-hook': 'review'})\n",
    "    page_data = []\n",
    "    for review in reviews:\n",
    "        profile_name = review.find(\"span\", {\"class\": \"a-profile-name\"}).get_text()\n",
    "        title_elem = review.find(\"a\", {\"data-hook\": \"review-title\"})\n",
    "        title = title_elem.get_text().strip() if title_elem else \"\"\n",
    "        body = review.find(\"span\", {\"data-hook\": \"review-body\"}).get_text().strip()\n",
    "        stars_elem = review.find(\"i\", {\"data-hook\": \"review-star-rating\"})\n",
    "        stars = float(stars_elem.span.get_text().split()[0]) if stars_elem and stars_elem.span else None\n",
    "        if stars==None:\n",
    "            stars_elem = review.find(\"i\", {\"data-hook\": \"cmps-review-star-rating\"})\n",
    "            stars = float(stars_elem.span.get_text().split()[0]) if stars_elem and stars_elem.span else None\n",
    "        page_data.append([profile_name, title, body, stars])\n",
    "\n",
    "    return page_data\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    page_num=math.ceil(float(reviews_count.replace(\",\",\"\"))/10)\n",
    "    pages = [f\"{URL_ALL_REVIEWS}+&pageNumber={i+1}\" for i in range(page_num)]\n",
    "    results = executor.map(scrape_reviews, pages)\n",
    "    for result in results:\n",
    "        data += result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parker S.</td>\n",
       "      <td>Cleaned my walls with this</td>\n",
       "      <td>I love this mixed in my mop bucket with warm w...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Karol Aguilar</td>\n",
       "      <td>good</td>\n",
       "      <td>good alternative to other brands, but the scen...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANIMALGIRL81</td>\n",
       "      <td>They smell so good.</td>\n",
       "      <td>Definitely make my laundry smell great! Will n...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Melissa Y Wood</td>\n",
       "      <td>Value</td>\n",
       "      <td>Smells great and decent price.</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Foxylady</td>\n",
       "      <td>Terrific product to drive away bad smells</td>\n",
       "      <td>Great little laundry deodorant. Just enough to...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name                                      Title  \\\n",
       "0       Parker S.                 Cleaned my walls with this   \n",
       "1   Karol Aguilar                                       good   \n",
       "2    ANIMALGIRL81                        They smell so good.   \n",
       "3  Melissa Y Wood                                      Value   \n",
       "4        Foxylady  Terrific product to drive away bad smells   \n",
       "\n",
       "                                                Body  Stars  \n",
       "0  I love this mixed in my mop bucket with warm w...    5.0  \n",
       "1  good alternative to other brands, but the scen...    5.0  \n",
       "2  Definitely make my laundry smell great! Will n...    5.0  \n",
       "3                     Smells great and decent price.    5.0  \n",
       "4  Great little laundry deodorant. Just enough to...    5.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=['Name', 'Title', 'Body', 'Stars'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.897475242614746\n"
     ]
    }
   ],
   "source": [
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "806"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, PromptTemplate, LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "text_splitter = CharacterTextSplitter()\n",
    "\n",
    "\n",
    "# Define function to generate summary\n",
    "def generate_summary(all_text) -> str:\n",
    "    texts = text_splitter.split_text(all_text)\n",
    "    docs = [Document(page_content=t) for t in texts[:3]]\n",
    "    chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "    summary=chain.run(docs)\n",
    "    return summary\n",
    "\n",
    "# Print summary\n",
    "def chunks_summary(text_chunks):\n",
    "    # Generate summaries for each text chunk and combine them\n",
    "    text_chunks=chunk_data(text_chunks,15000) #16122 #15800\n",
    "    #print(len(text_chunks))\n",
    "    summaries = []\n",
    "    for chunk in text_chunks:\n",
    "        summary = generate_summary(chunk)\n",
    "        #print(f\"Chunk len: {len(chunk)}, Summary len: {len(summary)}\")\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    if len(summaries)!=1:\n",
    "        return chunks_summary(summaries)\n",
    "    else:\n",
    "        return summaries[0]\n",
    "    # combined_summary = \" \".join(summaries)\n",
    "    # overall_summary=generate_summary(combined_summary)\n",
    "\n",
    "\n",
    "def chunk_data(data, max_len) -> list: \n",
    "\n",
    "    res = []\n",
    "    c_chuck = \"\"\n",
    "\n",
    "    for review in data:\n",
    "        \n",
    "        if len(c_chuck+review)>max_len:\n",
    "            if c_chuck:\n",
    "                res.append(c_chuck)\n",
    "                c_chuck = \"\"\n",
    "\n",
    "        if len(review) > max_len:\n",
    "            while len(review) > max_len:\n",
    "                res.append(review[:max_len])\n",
    "                review = review[max_len:]\n",
    "            res.append(review)\n",
    "            c_chuck = \"\"\n",
    "\n",
    "        else:\n",
    "            c_chuck+=review\n",
    "\n",
    "    if c_chuck:\n",
    "        res.append(c_chuck)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "summary_of_product=chunks_summary(''.join(df['Body'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arm & Hammer Clean Scentsations In-Wash Scent Booster Tropical Paradise is an economical and effective laundry scent booster with a pleasant scent that lasts. It is a great value for the price and is easy to use, but some users have found that the scent does not last long. It is also good for removing odors from work clothes and is gentle on sensitive skin, but some customers have found the scent too strong or not long-lasting enough.\n"
     ]
    }
   ],
   "source": [
    "print(summary_of_product[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parker S.</td>\n",
       "      <td>Cleaned my walls with this</td>\n",
       "      <td>I love this mixed in my mop bucket with warm w...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Karol Aguilar</td>\n",
       "      <td>good</td>\n",
       "      <td>good alternative to other brands, but the scen...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANIMALGIRL81</td>\n",
       "      <td>They smell so good.</td>\n",
       "      <td>Definitely make my laundry smell great! Will n...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Melissa Y Wood</td>\n",
       "      <td>Value</td>\n",
       "      <td>Smells great and decent price.</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Foxylady</td>\n",
       "      <td>Terrific product to drive away bad smells</td>\n",
       "      <td>Great little laundry deodorant. Just enough to...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name                                      Title  \\\n",
       "0       Parker S.                 Cleaned my walls with this   \n",
       "1   Karol Aguilar                                       good   \n",
       "2    ANIMALGIRL81                        They smell so good.   \n",
       "3  Melissa Y Wood                                      Value   \n",
       "4        Foxylady  Terrific product to drive away bad smells   \n",
       "\n",
       "                                                Body  Stars  \n",
       "0  I love this mixed in my mop bucket with warm w...    5.0  \n",
       "1  good alternative to other brands, but the scen...    5.0  \n",
       "2  Definitely make my laundry smell great! Will n...    5.0  \n",
       "3                     Smells great and decent price.    5.0  \n",
       "4  Great little laundry deodorant. Just enough to...    5.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os.path\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.file','https://www.googleapis.com/auth/drive']\n",
    "creds = None\n",
    "# The file token.json stores the user's access and refresh tokens, and is\n",
    "# created automatically when the authorization flow completes for the first\n",
    "# time.\n",
    "if os.path.exists('token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "# If there are no (valid) credentials available, let the user log in.\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            'credentials.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    # Save the credentials for the next run\n",
    "    with open('token.json', 'w') as token:\n",
    "        token.write(creds.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_service = build('drive', 'v3', credentials=creds)\n",
    "file_metadata = {\n",
    "    'name': 'My Document',\n",
    "    'parents': ['1lBmUcDPDAiMqyHt3lBIZSvpOkPN5L8Hc'],\n",
    "    'mimeType': 'application/vnd.google-apps.document'\n",
    "}\n",
    "document = docs_service.files().create(body=file_metadata).execute()\n",
    "document_id=document['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Google Docs API client\n",
    "docs_service = build('docs', 'v1', credentials=creds)\n",
    "\n",
    "\n",
    "# Create the table\n",
    "requests = [{\n",
    "    'insertTable': {\n",
    "        'rows': 1,\n",
    "        'columns':4,\n",
    "        'endOfSegmentLocation': {}\n",
    "    }\n",
    "}]\n",
    "\n",
    "try:\n",
    "    result = docs_service.documents().batchUpdate(documentId=document_id, body={'requests': requests}).execute()\n",
    "except HttpError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdoctableapppy import gdoctableapp\n",
    "table_data=[]\n",
    "table_data.append(df.columns.tolist())\n",
    "# loop over the rows\n",
    "for _, row in df.iterrows():\n",
    "    table_data.append([row['Name'], row['Title'], row['Body'],row['Stars']])\n",
    "\n",
    "table_data2 = [i[::-1] for i in table_data]\n",
    "\n",
    "resource = {\n",
    "    \"oauth2\": creds,\n",
    "    \"documentId\": document_id,\n",
    "    \"tableIndex\": 0,\n",
    "    \"values\": table_data2\n",
    "}\n",
    "\n",
    "res = gdoctableapp.SetValues(resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://drive.google.com/file/d/1Ie-QcR3UtIuZje6H8mTWciYciUDMtCa26c6rXQpBJTg/view?usp=sharing\n"
     ]
    }
   ],
   "source": [
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# Set up permission metadata\n",
    "permission_metadata = {\n",
    "    'role': 'reader',\n",
    "    'type': 'anyone',\n",
    "}\n",
    "\n",
    "# Create the permission\n",
    "permission = drive_service.permissions().create(\n",
    "    fileId=document_id,\n",
    "    body=permission_metadata,\n",
    "    fields='id'\n",
    ").execute()\n",
    "\n",
    "# Get the permission ID\n",
    "permission_id = permission['id']\n",
    "\n",
    "# Generate the link\n",
    "link = f'https://drive.google.com/file/d/{document_id}/view?usp=sharing'\n",
    "print(link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "141b6056e70a629fcfc37c76d11309ae0ce23d1be763896081c7bf037e6ba981"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
